---
phase: 08-delta50-setup
plan: 02
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - src/qm_nmr_calc/benchmark/runner.py
  - src/qm_nmr_calc/benchmark/__main__.py
  - src/qm_nmr_calc/benchmark/__init__.py
autonomous: true

must_haves:
  truths:
    - "CLI command `python -m qm_nmr_calc.benchmark run` executes benchmark"
    - "Runner creates results in data/benchmark/results/{molecule_id}/{FUNCTIONAL}_{SOLVENT}/"
    - "Resume mode skips molecules with existing shifts.json"
    - "Failed calculations log error and continue to next molecule"
    - "Summary CSV/JSON generated after run completes"
  artifacts:
    - path: "src/qm_nmr_calc/benchmark/runner.py"
      provides: "Sequential benchmark runner with resume support"
      exports: ["run_benchmark", "build_task_matrix"]
    - path: "src/qm_nmr_calc/benchmark/__main__.py"
      provides: "CLI entry point with argparse"
      min_lines: 30
  key_links:
    - from: "src/qm_nmr_calc/benchmark/runner.py"
      to: "qm_nmr_calc.nwchem.run_calculation"
      via: "import and call"
      pattern: "run_calculation"
    - from: "src/qm_nmr_calc/benchmark/runner.py"
      to: "data/benchmark/results/"
      via: "Path resolution and mkdir"
      pattern: "results.*mkdir"
---

<objective>
Create benchmark runner with CLI for executing DELTA50 calculation matrix

Purpose: Enable execution of 50 molecules x 2 functionals x 2 solvents (200 calculations) with resume support, progress tracking, and summary generation.
Output: runner.py with run_benchmark(), __main__.py with CLI, updated __init__.py exports
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-delta50-setup/08-CONTEXT.md
@.planning/phases/08-delta50-setup/08-RESEARCH.md

# From prior plan
@.planning/phases/08-delta50-setup/08-01-SUMMARY.md

# Existing codebase patterns
@src/qm_nmr_calc/nwchem/runner.py
@src/qm_nmr_calc/presets.py
@src/qm_nmr_calc/shifts.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create benchmark runner with resume support</name>
  <files>
    src/qm_nmr_calc/benchmark/runner.py
  </files>
  <action>
Create `src/qm_nmr_calc/benchmark/runner.py` with sequential execution and resume support:

```python
"""Benchmark runner for DELTA50 calculation matrix."""
import json
import logging
from pathlib import Path
from typing import Literal
from tqdm import tqdm
import pandas as pd

from qm_nmr_calc.nwchem import run_calculation, load_geometry_file
from qm_nmr_calc.shifts import shielding_to_shift
from .data_loader import load_delta50_molecules, load_experimental_shifts, get_data_dir
from .models import BenchmarkResult

logger = logging.getLogger(__name__)

# Benchmark configuration
FUNCTIONALS = ["B3LYP", "WP04"]
SOLVENTS = ["CHCl3", "DMSO"]

# Preset configurations for benchmark (not using existing presets.py - need WP04)
BENCHMARK_PRESETS = {
    "B3LYP": {
        "functional": "b3lyp",
        "basis_set": "6-31G*",
        "nmr_basis_set": "6-311+G(2d,p)",
        "max_iter": 150,
    },
    "WP04": {
        "functional": "wp04",  # Optimized for 1H shifts
        "basis_set": "6-31G*",
        "nmr_basis_set": "6-311++G(2d,p)",  # DELTA50 used this for WP04
        "max_iter": 150,
    },
}


def get_results_dir() -> Path:
    """Get path to benchmark results directory."""
    return get_data_dir().parent / "results"


def build_task_matrix(
    molecules: list[str] | None = None,
    functionals: list[str] | None = None,
    solvents: list[str] | None = None,
) -> list[dict]:
    """Build list of all benchmark tasks.

    Args:
        molecules: Specific molecule IDs to include (default: all 50)
        functionals: Functionals to test (default: B3LYP, WP04)
        solvents: Solvents to test (default: CHCl3, DMSO)

    Returns:
        List of task dicts with keys: molecule_id, functional, solvent, task_id
    """
    if functionals is None:
        functionals = FUNCTIONALS
    if solvents is None:
        solvents = SOLVENTS

    # Load molecule list if not specified
    if molecules is None:
        exp_shifts = load_experimental_shifts()
        molecules = sorted(exp_shifts.molecules.keys())

    tasks = []
    for mol_id in molecules:
        for func in functionals:
            for solv in solvents:
                task_id = f"{mol_id}_{func}_{solv}"
                tasks.append({
                    "task_id": task_id,
                    "molecule_id": mol_id,
                    "functional": func,
                    "solvent": solv,
                })

    return tasks


def is_task_complete(results_dir: Path, task: dict) -> bool:
    """Check if a task has already completed successfully.

    Checks for shifts.json marker file in the output directory.
    """
    output_dir = results_dir / task["molecule_id"] / f"{task['functional']}_{task['solvent']}"
    shifts_file = output_dir / "shifts.json"
    return shifts_file.exists()


def append_to_jsonl(filepath: Path, data: dict) -> None:
    """Append a result to JSONL progress file."""
    filepath.parent.mkdir(parents=True, exist_ok=True)
    with filepath.open("a") as f:
        f.write(json.dumps(data) + "\n")


def run_single_calculation(
    mol_id: str,
    functional: str,
    solvent: str,
    results_dir: Path,
    processes: int = 4,
) -> BenchmarkResult:
    """Run a single benchmark calculation.

    Args:
        mol_id: Molecule ID (e.g., "molecule_01")
        functional: Functional name (B3LYP or WP04)
        solvent: Solvent name (CHCl3 or DMSO)
        results_dir: Base results directory
        processes: Number of MPI processes

    Returns:
        BenchmarkResult with calculated shifts or error info
    """
    output_dir = results_dir / mol_id / f"{functional}_{solvent}"
    output_dir.mkdir(parents=True, exist_ok=True)

    # Load molecule geometry
    xyz_dir = get_data_dir() / "molecules"
    xyz_file = xyz_dir / f"{mol_id}.xyz"

    if not xyz_file.exists():
        return BenchmarkResult(
            molecule_id=mol_id,
            functional=functional,
            basis_set=BENCHMARK_PRESETS[functional]["nmr_basis_set"],
            solvent=solvent,
            calculated_h1=[],
            calculated_c13=[],
            status="failed",
            error=f"XYZ file not found: {xyz_file}",
        )

    try:
        # Get preset for this functional
        preset = BENCHMARK_PRESETS[functional]

        # Run NWChem calculation
        # Note: We need to pass SMILES for run_calculation, but we have XYZ
        # Use skip_optimization=True with geometry_file to use pre-optimized coords
        result = run_calculation(
            smiles="",  # Not used when skip_optimization=True
            job_dir=output_dir,
            preset=preset,
            solvent=solvent.lower(),  # COSMO expects lowercase
            processes=processes,
            skip_optimization=True,
            geometry_file=xyz_file,
        )

        # Convert shielding to shifts
        # Use production scaling for now (will derive benchmark-specific later)
        shifts_data = shielding_to_shift(result["shielding_data"], preset="production")

        # Extract shift values
        h1_shifts = [s["shift"] for s in shifts_data["1H"]]
        c13_shifts = [s["shift"] for s in shifts_data["13C"]]

        # Save shifts to JSON
        shifts_output = {
            "molecule_id": mol_id,
            "functional": functional,
            "solvent": solvent,
            "h1_shifts": h1_shifts,
            "c13_shifts": c13_shifts,
            "shielding_data": result["shielding_data"],
        }
        shifts_file = output_dir / "shifts.json"
        with shifts_file.open("w") as f:
            json.dump(shifts_output, f, indent=2)

        # Copy NWChem files to output dir for reference
        # (run_calculation creates them in output_dir/scratch already)

        return BenchmarkResult(
            molecule_id=mol_id,
            functional=functional,
            basis_set=preset["nmr_basis_set"],
            solvent=solvent,
            calculated_h1=h1_shifts,
            calculated_c13=c13_shifts,
            status="complete",
        )

    except Exception as e:
        logger.error(f"Calculation failed for {mol_id}/{functional}/{solvent}: {e}")
        return BenchmarkResult(
            molecule_id=mol_id,
            functional=functional,
            basis_set=BENCHMARK_PRESETS[functional]["nmr_basis_set"],
            solvent=solvent,
            calculated_h1=[],
            calculated_c13=[],
            status="failed",
            error=str(e),
        )


def run_benchmark(
    resume: bool = True,
    molecules: list[str] | None = None,
    functionals: list[str] | None = None,
    solvents: list[str] | None = None,
    processes: int = 4,
) -> list[BenchmarkResult]:
    """Execute DELTA50 benchmark calculation matrix.

    Args:
        resume: If True, skip already-completed calculations
        molecules: Specific molecule IDs to run (default: all 50)
        functionals: Functionals to test (default: B3LYP, WP04)
        solvents: Solvents to test (default: CHCl3, DMSO)
        processes: Number of MPI processes per calculation

    Returns:
        List of BenchmarkResult for all executed tasks
    """
    results_dir = get_results_dir()
    results_dir.mkdir(parents=True, exist_ok=True)
    progress_file = results_dir / "progress.jsonl"

    # Build task matrix
    tasks = build_task_matrix(molecules, functionals, solvents)

    # Filter if resuming
    if resume:
        tasks = [t for t in tasks if not is_task_complete(results_dir, t)]

    if not tasks:
        logger.info("No tasks to run (all complete or empty task list)")
        return []

    logger.info(f"Running {len(tasks)} benchmark calculations")

    results = []
    for task in tqdm(tasks, desc="DELTA50 Benchmark"):
        result = run_single_calculation(
            mol_id=task["molecule_id"],
            functional=task["functional"],
            solvent=task["solvent"],
            results_dir=results_dir,
            processes=processes,
        )
        results.append(result)

        # Log progress to JSONL
        append_to_jsonl(progress_file, {
            "task_id": task["task_id"],
            "status": result.status,
            "error": result.error,
        })

    return results


def aggregate_results(output_file: Path | None = None) -> pd.DataFrame:
    """Aggregate all benchmark results into summary DataFrame.

    Args:
        output_file: If provided, write CSV to this path

    Returns:
        DataFrame with all results
    """
    results_dir = get_results_dir()
    records = []

    for mol_dir in sorted(results_dir.glob("molecule_*")):
        for method_dir in mol_dir.glob("*_*"):
            shifts_file = method_dir / "shifts.json"
            if not shifts_file.exists():
                continue

            with shifts_file.open() as f:
                data = json.load(f)

            # Parse directory names
            molecule_id = mol_dir.name
            parts = method_dir.name.split("_", 1)
            if len(parts) == 2:
                functional, solvent = parts
            else:
                continue

            records.append({
                "molecule_id": molecule_id,
                "functional": functional,
                "solvent": solvent,
                "num_h1": len(data.get("h1_shifts", [])),
                "num_c13": len(data.get("c13_shifts", [])),
            })

    df = pd.DataFrame(records)

    if output_file:
        output_file.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(output_file, index=False)
        logger.info(f"Summary written to {output_file} ({len(records)} results)")

    return df


def show_status() -> None:
    """Print benchmark progress status."""
    results_dir = get_results_dir()

    # Count completed tasks
    total_tasks = 50 * len(FUNCTIONALS) * len(SOLVENTS)  # 200

    completed = 0
    for mol_dir in results_dir.glob("molecule_*"):
        for method_dir in mol_dir.glob("*_*"):
            if (method_dir / "shifts.json").exists():
                completed += 1

    print(f"DELTA50 Benchmark Status")
    print(f"========================")
    print(f"Completed: {completed}/{total_tasks} ({100*completed/total_tasks:.1f}%)")
    print(f"Remaining: {total_tasks - completed}")
    print(f"Results directory: {results_dir}")
```

Key design points:
- BENCHMARK_PRESETS separate from presets.py to include WP04 functional
- Resume checks for shifts.json marker file specifically
- tqdm progress bar for visual feedback
- JSONL progress file for crash recovery tracking
- Skip geometry optimization (use DELTA50 optimized structures directly)
- shielding_to_shift uses production scaling (benchmark-specific scaling derived later in Phase 10)
  </action>
  <verify>
```bash
python -c "from qm_nmr_calc.benchmark.runner import build_task_matrix, FUNCTIONALS, SOLVENTS; tasks = build_task_matrix(); print(f'Task matrix: {len(tasks)} tasks ({len(tasks)//len(FUNCTIONALS)//len(SOLVENTS)} molecules x {len(FUNCTIONALS)} functionals x {len(SOLVENTS)} solvents)')"
```
  </verify>
  <done>runner.py created with run_benchmark(), resume support, progress tracking, and aggregation</done>
</task>

<task type="auto">
  <name>Task 2: Create CLI entry point</name>
  <files>
    src/qm_nmr_calc/benchmark/__main__.py
    src/qm_nmr_calc/benchmark/__init__.py
  </files>
  <action>
Create `src/qm_nmr_calc/benchmark/__main__.py` with argparse subcommands:

```python
"""CLI entry point for DELTA50 benchmark runner.

Usage:
    python -m qm_nmr_calc.benchmark run [--resume] [--molecules M1 M2 ...]
    python -m qm_nmr_calc.benchmark status
    python -m qm_nmr_calc.benchmark summary [--output FILE]
"""
import argparse
import logging
import sys

from .runner import run_benchmark, show_status, aggregate_results, get_results_dir


def setup_logging(verbose: bool = False) -> None:
    """Configure logging for CLI."""
    level = logging.DEBUG if verbose else logging.INFO
    logging.basicConfig(
        level=level,
        format="%(asctime)s - %(levelname)s - %(message)s",
        datefmt="%H:%M:%S",
    )


def cmd_run(args: argparse.Namespace) -> int:
    """Execute benchmark calculations."""
    setup_logging(args.verbose)

    molecules = args.molecules if args.molecules else None
    functionals = args.functionals if args.functionals else None
    solvents = args.solvents if args.solvents else None

    results = run_benchmark(
        resume=args.resume,
        molecules=molecules,
        functionals=functionals,
        solvents=solvents,
        processes=args.processes,
    )

    # Print summary
    completed = sum(1 for r in results if r.status == "complete")
    failed = sum(1 for r in results if r.status == "failed")

    print(f"\nBenchmark run complete:")
    print(f"  Completed: {completed}")
    print(f"  Failed: {failed}")

    if failed > 0:
        print("\nFailed calculations:")
        for r in results:
            if r.status == "failed":
                print(f"  - {r.molecule_id}/{r.functional}/{r.solvent}: {r.error}")

    return 0 if failed == 0 else 1


def cmd_status(args: argparse.Namespace) -> int:
    """Show benchmark progress."""
    show_status()
    return 0


def cmd_summary(args: argparse.Namespace) -> int:
    """Generate summary CSV."""
    setup_logging(args.verbose)

    output = args.output
    if output is None:
        output = get_results_dir() / "summary.csv"

    df = aggregate_results(output)
    print(f"Summary generated: {len(df)} results")
    print(df.to_string(index=False))
    return 0


def main() -> int:
    """Main CLI entry point."""
    parser = argparse.ArgumentParser(
        prog="python -m qm_nmr_calc.benchmark",
        description="DELTA50 benchmark runner for NMR shift validation",
    )
    parser.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Enable verbose logging",
    )

    subparsers = parser.add_subparsers(dest="command", required=True)

    # run subcommand
    run_parser = subparsers.add_parser(
        "run",
        help="Execute benchmark calculations",
    )
    run_parser.add_argument(
        "--resume",
        action="store_true",
        default=True,
        help="Skip completed calculations (default: True)",
    )
    run_parser.add_argument(
        "--no-resume",
        action="store_false",
        dest="resume",
        help="Re-run all calculations",
    )
    run_parser.add_argument(
        "--molecules",
        nargs="+",
        help="Specific molecule IDs to run (default: all 50)",
    )
    run_parser.add_argument(
        "--functionals",
        nargs="+",
        choices=["B3LYP", "WP04"],
        help="Functionals to test (default: B3LYP WP04)",
    )
    run_parser.add_argument(
        "--solvents",
        nargs="+",
        choices=["CHCl3", "DMSO"],
        help="Solvents to test (default: CHCl3 DMSO)",
    )
    run_parser.add_argument(
        "--processes",
        type=int,
        default=4,
        help="Number of MPI processes per calculation (default: 4)",
    )
    run_parser.set_defaults(func=cmd_run)

    # status subcommand
    status_parser = subparsers.add_parser(
        "status",
        help="Show benchmark progress",
    )
    status_parser.set_defaults(func=cmd_status)

    # summary subcommand
    summary_parser = subparsers.add_parser(
        "summary",
        help="Generate summary CSV from results",
    )
    summary_parser.add_argument(
        "--output", "-o",
        type=str,
        help="Output CSV file path (default: data/benchmark/results/summary.csv)",
    )
    summary_parser.set_defaults(func=cmd_summary)

    args = parser.parse_args()
    return args.func(args)


if __name__ == "__main__":
    sys.exit(main())
```

Update `src/qm_nmr_calc/benchmark/__init__.py` to export runner functions:

```python
"""DELTA50 benchmark infrastructure for NMR shift validation."""
from .models import MoleculeData, ExperimentalShifts, BenchmarkResult
from .data_loader import load_delta50_molecules, load_experimental_shifts, get_data_dir
from .runner import run_benchmark, build_task_matrix, show_status, aggregate_results

__all__ = [
    # Models
    "MoleculeData",
    "ExperimentalShifts",
    "BenchmarkResult",
    # Data loading
    "load_delta50_molecules",
    "load_experimental_shifts",
    "get_data_dir",
    # Runner
    "run_benchmark",
    "build_task_matrix",
    "show_status",
    "aggregate_results",
]
```
  </action>
  <verify>
```bash
# Test CLI help
python -m qm_nmr_calc.benchmark --help
python -m qm_nmr_calc.benchmark run --help
python -m qm_nmr_calc.benchmark status --help
python -m qm_nmr_calc.benchmark summary --help

# Test status command (should work even with no results)
python -m qm_nmr_calc.benchmark status

# Test imports
python -c "from qm_nmr_calc.benchmark import run_benchmark, show_status, aggregate_results; print('All exports available')"
```
  </verify>
  <done>CLI works with run/status/summary subcommands, all functions exported from __init__.py</done>
</task>

<task type="auto">
  <name>Task 3: Add unit tests for benchmark module</name>
  <files>
    tests/test_benchmark.py
  </files>
  <action>
Create `tests/test_benchmark.py` with unit tests for the benchmark module:

```python
"""Tests for DELTA50 benchmark infrastructure."""
import json
from pathlib import Path
import pytest

from qm_nmr_calc.benchmark import (
    load_experimental_shifts,
    load_delta50_molecules,
    get_data_dir,
    build_task_matrix,
    MoleculeData,
    ExperimentalShifts,
    BenchmarkResult,
)
from qm_nmr_calc.benchmark.runner import (
    FUNCTIONALS,
    SOLVENTS,
    BENCHMARK_PRESETS,
    is_task_complete,
)


class TestDataLoader:
    """Tests for data_loader module."""

    def test_get_data_dir_exists(self):
        """Data directory should exist."""
        data_dir = get_data_dir()
        assert data_dir.exists(), f"Data directory not found: {data_dir}"

    def test_load_experimental_shifts(self):
        """Should load all 50 molecules with experimental data."""
        shifts = load_experimental_shifts()
        assert isinstance(shifts, ExperimentalShifts)
        assert len(shifts.molecules) == 50, f"Expected 50 molecules, got {len(shifts.molecules)}"
        assert "doi" in shifts.source

    def test_load_experimental_shifts_has_h1_data(self):
        """Each molecule should have H1 shift data."""
        shifts = load_experimental_shifts()
        for mol_id, mol in shifts.molecules.items():
            assert len(mol.h1_shifts) > 0, f"Molecule {mol_id} has no 1H shifts"

    def test_load_experimental_shifts_has_c13_data(self):
        """Each molecule should have C13 shift data."""
        shifts = load_experimental_shifts()
        for mol_id, mol in shifts.molecules.items():
            assert len(mol.c13_shifts) > 0, f"Molecule {mol_id} has no 13C shifts"

    def test_load_delta50_molecules(self):
        """Should load all 50 molecule structures."""
        molecules = load_delta50_molecules()
        assert len(molecules) == 50, f"Expected 50 molecules, got {len(molecules)}"

    def test_load_delta50_molecules_returns_rdkit_mol(self):
        """Each molecule should be a valid RDKit mol with XYZ block."""
        molecules = load_delta50_molecules()
        for mol_id, (mol, xyz_block) in molecules.items():
            assert mol is not None, f"Molecule {mol_id} is None"
            assert mol.GetNumAtoms() > 0, f"Molecule {mol_id} has no atoms"
            assert isinstance(xyz_block, str), f"XYZ block for {mol_id} is not string"


class TestModels:
    """Tests for Pydantic models."""

    def test_molecule_data_creation(self):
        """MoleculeData should validate correctly."""
        mol = MoleculeData(
            id="test_01",
            name="Test Molecule",
            xyz_file="molecules/test_01.xyz",
            h1_shifts=[7.26, 3.45],
            c13_shifts=[128.5, 45.2],
        )
        assert mol.id == "test_01"
        assert len(mol.h1_shifts) == 2

    def test_benchmark_result_creation(self):
        """BenchmarkResult should validate correctly."""
        result = BenchmarkResult(
            molecule_id="test_01",
            functional="B3LYP",
            basis_set="6-311+G(2d,p)",
            solvent="CHCl3",
            calculated_h1=[7.30, 3.50],
            calculated_c13=[130.0, 46.0],
            status="complete",
        )
        assert result.molecule_id == "test_01"
        assert result.status == "complete"


class TestRunner:
    """Tests for benchmark runner."""

    def test_benchmark_presets_defined(self):
        """Both B3LYP and WP04 presets should be defined."""
        assert "B3LYP" in BENCHMARK_PRESETS
        assert "WP04" in BENCHMARK_PRESETS

    def test_benchmark_presets_have_required_keys(self):
        """Presets should have all required configuration keys."""
        required_keys = {"functional", "basis_set", "nmr_basis_set", "max_iter"}
        for name, preset in BENCHMARK_PRESETS.items():
            missing = required_keys - set(preset.keys())
            assert not missing, f"Preset {name} missing keys: {missing}"

    def test_build_task_matrix_default(self):
        """Default matrix should be 50 molecules x 2 functionals x 2 solvents."""
        tasks = build_task_matrix()
        expected = 50 * len(FUNCTIONALS) * len(SOLVENTS)
        assert len(tasks) == expected, f"Expected {expected} tasks, got {len(tasks)}"

    def test_build_task_matrix_filtered(self):
        """Should filter by molecules, functionals, solvents."""
        tasks = build_task_matrix(
            molecules=["molecule_01", "molecule_02"],
            functionals=["B3LYP"],
            solvents=["CHCl3"],
        )
        assert len(tasks) == 2, f"Expected 2 tasks, got {len(tasks)}"

    def test_task_has_required_keys(self):
        """Each task should have task_id, molecule_id, functional, solvent."""
        tasks = build_task_matrix()
        for task in tasks[:5]:  # Check first 5
            assert "task_id" in task
            assert "molecule_id" in task
            assert "functional" in task
            assert "solvent" in task

    def test_is_task_complete_false_when_no_dir(self, tmp_path):
        """Task should not be complete if output dir doesn't exist."""
        task = {"molecule_id": "test", "functional": "B3LYP", "solvent": "CHCl3"}
        assert not is_task_complete(tmp_path, task)

    def test_is_task_complete_false_when_no_shifts_json(self, tmp_path):
        """Task should not be complete if shifts.json doesn't exist."""
        task = {"molecule_id": "test", "functional": "B3LYP", "solvent": "CHCl3"}
        output_dir = tmp_path / "test" / "B3LYP_CHCl3"
        output_dir.mkdir(parents=True)
        assert not is_task_complete(tmp_path, task)

    def test_is_task_complete_true_when_shifts_json_exists(self, tmp_path):
        """Task should be complete if shifts.json exists."""
        task = {"molecule_id": "test", "functional": "B3LYP", "solvent": "CHCl3"}
        output_dir = tmp_path / "test" / "B3LYP_CHCl3"
        output_dir.mkdir(parents=True)
        (output_dir / "shifts.json").write_text("{}")
        assert is_task_complete(tmp_path, task)
```

Run tests to verify:
```bash
pytest tests/test_benchmark.py -v
```
  </action>
  <verify>
```bash
pytest tests/test_benchmark.py -v --tb=short
```
  </verify>
  <done>All benchmark tests pass</done>
</task>

</tasks>

<verification>
After all tasks complete:

```bash
# Verify CLI works
python -m qm_nmr_calc.benchmark --help
python -m qm_nmr_calc.benchmark status

# Verify task matrix
python -c "
from qm_nmr_calc.benchmark import build_task_matrix
tasks = build_task_matrix()
print(f'Total tasks: {len(tasks)}')
print(f'First task: {tasks[0]}')
print(f'Last task: {tasks[-1]}')
"

# Verify all tests pass
pytest tests/test_benchmark.py -v

# Dry-run with single molecule to verify runner structure
python -c "
from qm_nmr_calc.benchmark.runner import run_single_calculation, get_results_dir
from pathlib import Path
import tempfile

# Just verify the function signature works
print(f'Results directory would be: {get_results_dir()}')
print('Runner module imports and functions accessible')
"
```
</verification>

<success_criteria>
1. CLI `python -m qm_nmr_calc.benchmark run --help` shows all options
2. CLI `python -m qm_nmr_calc.benchmark status` shows 0/200 complete (no runs yet)
3. build_task_matrix() returns 200 tasks (50 x 2 x 2)
4. Runner has resume support via is_task_complete()
5. All unit tests pass
6. WP04 functional preset defined alongside B3LYP
</success_criteria>

<output>
After completion, create `.planning/phases/08-delta50-setup/08-02-SUMMARY.md`
</output>
