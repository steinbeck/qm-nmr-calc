---
phase: 50-machine-selection-and-resource-calculation
plan: 01
type: tdd
wave: 1
depends_on: []
files_modified:
  - gcp/select_machine.py
  - tests/test_gcp_machine.py
autonomous: true

must_haves:
  truths:
    - "Given CPU/RAM requirements, system returns the correct GCP machine type name"
    - "Given a zone, system validates whether the requested machine type exists there"
    - "When primary zone lacks the machine type, system tries next-cheapest zone and succeeds"
    - "Docker memory limit equals VM RAM minus 8GB OS overhead, with 'g' suffix"
    - "NWCHEM_NPROC matches the machine type's CPU count"
    - "Startup script template contains computed WORKER_MEMORY_LIMIT and uses nproc for CPU detection"
  artifacts:
    - path: "gcp/select_machine.py"
      provides: "Machine type selection, validation, fallback, resource calculation, startup script generation"
      exports: ["select_machine_type", "validate_machine_in_zone", "find_available_zone", "calculate_docker_resources", "generate_startup_script"]
    - path: "tests/test_gcp_machine.py"
      provides: "Tests for all machine selection and resource calculation logic"
      min_lines: 100
  key_links:
    - from: "gcp/select_machine.py"
      to: "gcp/query_pricing.py"
      via: "imports get_ranked_regions for fallback zone iteration"
      pattern: "from gcp\\.query_pricing import get_ranked_regions"
    - from: "gcp/select_machine.py"
      to: "gcp/validate_config.py"
      via: "uses GCPConfig model for type safety"
      pattern: "from gcp\\.validate_config import GCPConfig"
---

<objective>
Machine type selection, zone validation with fallback, Docker resource calculation, and startup script generation -- all as a testable Python module following the Phase 49 pattern.

Purpose: This is the core logic that maps user config (CPU/RAM) to the right GCP machine type, validates availability across zones, calculates Docker memory limits, and generates the startup script. All of this logic has defined inputs/outputs and must be correct -- TDD ensures it.

Output: `gcp/select_machine.py` with full test coverage in `tests/test_gcp_machine.py`
</objective>

<execution_context>
@/Users/steinbeck/.claude/get-shit-done/workflows/execute-plan.md
@/Users/steinbeck/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/50-machine-selection-and-resource-calculation/50-RESEARCH.md
@gcp/validate_config.py
@gcp/query_pricing.py
@gcp/startup.sh
@tests/test_gcp_config.py
@tests/test_gcp_pricing.py
</context>

<feature>
  <name>Machine Type Selection and Resource Calculation</name>
  <files>gcp/select_machine.py, tests/test_gcp_machine.py</files>
  <behavior>
    The module provides five core functions. All gcloud interactions are isolated behind
    helper functions so tests can mock them without subprocess calls.

    **1. select_machine_type(cpu_cores, ram_gb, zone) -> str**
    Maps CPU/RAM requirements to the cheapest GCP machine type in a zone.
    Calls `gcloud compute machine-types list --zones=ZONE --filter="guestCpus>=CPU AND memoryMb>=RAM_MB" --format=json --sort-by=memoryMb --limit=1 --quiet`.
    Returns machine type name (e.g., "n2-standard-8") or raises ValueError if none found.

    Cases:
    - select_machine_type(8, 32, "us-central1-a") with gcloud returning [{"name":"n2-standard-8","guestCpus":8,"memoryMb":32768}] -> "n2-standard-8"
    - select_machine_type(8, 32, "us-central1-a") with gcloud returning [] -> raises ValueError("No machine types found")
    - select_machine_type(8, 32, "us-central1-a") with gcloud command failing -> raises RuntimeError

    **2. validate_machine_in_zone(machine_type, zone) -> bool**
    Checks if a specific machine type exists in a zone.
    Calls `gcloud compute machine-types list --zones=ZONE --filter="name=MACHINE_TYPE" --format="value(name)" --quiet`.

    Cases:
    - validate_machine_in_zone("n2-standard-8", "us-central1-a") with gcloud returning "n2-standard-8" -> True
    - validate_machine_in_zone("n2-standard-8", "us-central1-a") with gcloud returning "" -> False

    **3. find_available_zone(cpu_cores, ram_gb, ranked_regions) -> dict**
    Iterates through ranked regions (from pricing query), tries select_machine_type in each.
    Returns dict with keys: zone, region, machine_type.
    Raises RuntimeError if ALL regions exhausted.

    Cases:
    - find_available_zone(8, 32, [{zone:"us-central1-a",...}, {zone:"us-east4-a",...}]) where first zone has machine type -> {"zone":"us-central1-a", "region":"us-central1", "machine_type":"n2-standard-8"}
    - find_available_zone(8, 32, [{zone:"us-central1-a",...}, {zone:"us-east4-a",...}]) where first zone fails, second succeeds -> returns second zone info
    - find_available_zone(8, 32, [{zone:"us-central1-a",...}]) where all fail -> raises RuntimeError("All regions exhausted")

    **4. calculate_docker_resources(machine_type, zone) -> dict**
    Queries machine type specs via `gcloud compute machine-types describe`, calculates Docker limits.
    Returns dict: {"worker_memory_limit": "24g", "nwchem_nproc": 8, "total_ram_gb": 32, "total_cpus": 8}

    Calculation: worker_memory_limit = (memoryMb / 1024) - 8, with "g" suffix.
    Minimum worker memory is 4GB (total RAM must be >= 12GB).
    nwchem_nproc = guestCpus from machine type.

    Cases:
    - calculate_docker_resources("n2-standard-8", "us-central1-a") with gcloud returning memoryMb=32768, guestCpus=8 -> {"worker_memory_limit":"24g", "nwchem_nproc":8, "total_ram_gb":32, "total_cpus":8}
    - calculate_docker_resources("n2-highmem-4", "us-central1-a") with memoryMb=32768, guestCpus=4 -> {"worker_memory_limit":"24g", "nwchem_nproc":4, ...}
    - calculate_docker_resources with total_ram < 12GB -> raises ValueError("Insufficient RAM after OS overhead")

    **5. generate_startup_script(worker_memory_limit, resource_prefix, disk_size_gb) -> str**
    Generates a complete startup script as a string.
    The script should:
    - Use `nproc` at runtime to detect CPU count (not hardcoded)
    - Write WORKER_MEMORY_LIMIT (from parameter) and NWCHEM_NPROC (from nproc) to /opt/qm-nmr-calc/.env
    - Install Docker if not present
    - Pull images from GHCR
    - Download docker-compose.yml from GitHub
    - Create HTTP-only docker-compose.gcp.yml override (port 80, no Caddy/HTTPS)
    - Start services with docker compose

    Cases:
    - generate_startup_script("24g", "qm-nmr-calc", 100) -> string containing "WORKER_MEMORY_LIMIT=24g" and "$(nproc)" and "docker compose"
    - Output script contains set -euo pipefail
    - Output script uses --oversubscribe for MPI (from v2.6 fix)

    **6. CLI interface**
    The module runs as a CLI script:
    `python3 gcp/select_machine.py --cpu-cores 8 --ram-gb 32 --zone us-central1-a`
    Outputs JSON: {"machine_type": "...", "zone": "...", "region": "...", "worker_memory_limit": "...", "nwchem_nproc": N}

    The CLI also supports `--generate-startup-script` flag to output the startup script instead.

    **Implementation notes:**
    - gcloud calls are wrapped in a helper `_run_gcloud(args) -> str` that runs subprocess and returns stdout.
      This single function is the mock target for ALL tests.
    - Use subprocess.run with capture_output=True, text=True, check=False.
    - Parse gcloud JSON output with json.loads().
    - Follow the same module pattern as validate_config.py and query_pricing.py (importable + CLI).
  </behavior>
  <implementation>
    Create gcp/select_machine.py with:

    1. _run_gcloud(args: list[str]) -> str: Runs gcloud with given args, returns stdout. Raises RuntimeError on non-zero exit.

    2. select_machine_type(cpu_cores: int, ram_gb: int, zone: str) -> str:
       - Convert ram_gb to ram_mb = ram_gb * 1024
       - Call _run_gcloud with machine-types list filter
       - Parse JSON, return first match name
       - Raise ValueError if empty result

    3. validate_machine_in_zone(machine_type: str, zone: str) -> bool:
       - Call _run_gcloud with name filter
       - Return True if output matches machine_type

    4. find_available_zone(cpu_cores: int, ram_gb: int, ranked_regions: list[dict]) -> dict:
       - Loop through ranked_regions
       - Try select_machine_type for each zone
       - On ValueError (no match) or RuntimeError (gcloud fail), continue to next
       - On success, return {zone, region, machine_type}
       - If all exhausted, raise RuntimeError

    5. calculate_docker_resources(machine_type: str, zone: str) -> dict:
       - Call _run_gcloud with machine-types describe, format json
       - Parse guestCpus and memoryMb
       - total_ram_gb = memoryMb // 1024
       - worker_memory_gb = total_ram_gb - 8
       - Validate worker_memory_gb >= 4
       - Return dict with worker_memory_limit=f"{worker_memory_gb}g", nwchem_nproc=guestCpus, total_ram_gb, total_cpus

    6. generate_startup_script(worker_memory_limit: str, resource_prefix: str, disk_size_gb: int) -> str:
       - Return a multiline string (here-doc style) with the complete startup script
       - Script uses nproc at runtime for CPU detection
       - Script writes .env, installs Docker, pulls images, creates compose override, starts services
       - Include --oversubscribe flag for MPI compatibility
       - HTTP only (port 80), no Caddy/HTTPS

    7. main() CLI: argparse with --cpu-cores, --ram-gb, --zone, --generate-startup-script, --resource-prefix, --disk-size-gb
       - Default mode: select machine type and calculate resources, output JSON
       - With --generate-startup-script: output startup script to stdout

    Test strategy:
    - Mock _run_gcloud using unittest.mock.patch for ALL tests
    - Provide realistic gcloud JSON responses as fixtures
    - Test each function independently with various gcloud outputs
    - Test find_available_zone fallback by having mock return error for first zone, success for second
    - Test calculate_docker_resources with various memory sizes
    - Test generate_startup_script output contains expected strings
    - Test CLI integration via main() with captured stdout
  </implementation>
</feature>

<verification>
```bash
# Run all Phase 50 tests
cd /Users/steinbeck/Dropbox/develop/qm-nmr-calc && python -m pytest tests/test_gcp_machine.py -v

# Run all GCP tests together to ensure no regressions
python -m pytest tests/test_gcp_config.py tests/test_gcp_pricing.py tests/test_gcp_machine.py -v

# Verify module is importable
python -c "from gcp.select_machine import select_machine_type, validate_machine_in_zone, find_available_zone, calculate_docker_resources, generate_startup_script; print('All imports OK')"

# Verify CLI runs (will fail without gcloud but should show usage)
python3 gcp/select_machine.py --help
```
</verification>

<success_criteria>
- All tests in test_gcp_machine.py pass
- All existing tests (test_gcp_config.py, test_gcp_pricing.py) still pass
- select_machine_type correctly maps CPU/RAM to machine type name from gcloud JSON
- validate_machine_in_zone returns bool based on gcloud output
- find_available_zone iterates regions and falls back on failure
- calculate_docker_resources subtracts 8GB OS overhead and returns "Xg" format
- generate_startup_script produces valid bash with nproc detection, .env creation, Docker setup, HTTP-only
- Module importable and runnable as CLI
- Requirements covered: MCH-01, MCH-02, MCH-03, MCH-04, PRC-02
</success_criteria>

<output>
After completion, create `.planning/phases/50-machine-selection-and-resource-calculation/50-01-SUMMARY.md`
</output>
