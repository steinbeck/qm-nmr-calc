---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - pyproject.toml
  - uv.lock
  - .python-version
  - src/qm_nmr_calc/__init__.py
  - src/qm_nmr_calc/models.py
  - src/qm_nmr_calc/storage.py
  - data/jobs/.gitkeep
autonomous: true

must_haves:
  truths:
    - "uv can install all dependencies including ISiCLE fork"
    - "Pydantic models validate job status correctly"
    - "Job directory can be created with proper structure"
    - "Job status.json can be read and written"
  artifacts:
    - path: "pyproject.toml"
      provides: "Project configuration with all dependencies"
      contains: "huey"
    - path: "src/qm_nmr_calc/models.py"
      provides: "Pydantic models for job status and input"
      exports: ["JobStatus", "JobInput"]
    - path: "src/qm_nmr_calc/storage.py"
      provides: "Job directory and status file management"
      exports: ["create_job_directory", "update_job_status", "load_job_status"]
  key_links:
    - from: "src/qm_nmr_calc/storage.py"
      to: "src/qm_nmr_calc/models.py"
      via: "imports JobStatus model"
      pattern: "from.*models import.*JobStatus"
---

<objective>
Initialize the qm-nmr-calc Python project with modern tooling and establish the data models and storage layer for job management.

Purpose: Create the foundation that all other Phase 1 code will build upon - the package structure, dependencies, and core abstractions for job state management.

Output: Working Python package with Pydantic models for job tracking and filesystem-based job storage.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/phases/01-foundation/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Initialize uv project with dependencies</name>
  <files>
    pyproject.toml
    uv.lock
    .python-version
    src/qm_nmr_calc/__init__.py
    data/jobs/.gitkeep
  </files>
  <action>
Initialize Python project using uv:

1. Run `uv init --name qm-nmr-calc` to create pyproject.toml
2. Set Python version: `echo "3.11" > .python-version`
3. Create src layout: `mkdir -p src/qm_nmr_calc`
4. Create `src/qm_nmr_calc/__init__.py` with version: `__version__ = "0.1.0"`
5. Add dependencies:
   - `uv add huey pydantic orjson`
   - `uv add rdkit` (not rdkit-pypi - that's deprecated)
   - `uv add -e ~/develop/isicle` (ISiCLE fork as editable install)
6. Create data directory: `mkdir -p data/jobs && touch data/jobs/.gitkeep`

Update pyproject.toml to use src layout:
```toml
[tool.setuptools.packages.find]
where = ["src"]
```

Verify with `uv run python -c "import qm_nmr_calc; print(qm_nmr_calc.__version__)"`.
  </action>
  <verify>
- `uv sync` completes without errors
- `uv run python -c "import huey, pydantic, orjson, rdkit, isicle"` succeeds
- `uv run python -c "import qm_nmr_calc"` succeeds
- `ls data/jobs/.gitkeep` exists
  </verify>
  <done>
- pyproject.toml exists with all dependencies
- uv.lock is generated
- Package imports successfully
- data/jobs directory ready for job storage
  </done>
</task>

<task type="auto">
  <name>Task 2: Create Pydantic models for job management</name>
  <files>src/qm_nmr_calc/models.py</files>
  <action>
Create `src/qm_nmr_calc/models.py` with Pydantic models:

**JobStatus model** (main status tracking):
```python
from pydantic import BaseModel
from datetime import datetime
from typing import Optional, Literal

class JobInput(BaseModel):
    """Input parameters for a calculation job."""
    smiles: str
    # Future: mol_file, parameters

class JobStatus(BaseModel):
    """Complete status of a calculation job."""
    job_id: str
    status: Literal['queued', 'running', 'complete', 'failed']
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None

    # Input
    input: JobInput

    # Versions (for reproducibility)
    isicle_version: str
    nwchem_version: str

    # Error info (if failed)
    error_message: Optional[str] = None
    error_traceback: Optional[str] = None

    # Resource usage (filled on completion)
    cpu_time_seconds: Optional[float] = None
    memory_peak_mb: Optional[float] = None
```

Use strict mode where appropriate. Add model_config for JSON serialization compatibility with orjson.
  </action>
  <verify>
```bash
uv run python -c "
from qm_nmr_calc.models import JobStatus, JobInput
from datetime import datetime

inp = JobInput(smiles='CCO')
job = JobStatus(
    job_id='test123',
    status='queued',
    created_at=datetime.utcnow(),
    input=inp,
    isicle_version='2.0.0',
    nwchem_version='7.0.2'
)
print(job.model_dump_json())
"
```
Should print valid JSON without errors.
  </verify>
  <done>
- JobInput model validates SMILES input
- JobStatus model validates all job state fields
- Models serialize to JSON correctly
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement job storage layer</name>
  <files>src/qm_nmr_calc/storage.py</files>
  <action>
Create `src/qm_nmr_calc/storage.py` with job directory management:

```python
from pathlib import Path
from datetime import datetime
from typing import Optional
import uuid
import orjson

from .models import JobStatus, JobInput

DATA_DIR = Path('./data/jobs')

def generate_job_id() -> str:
    """Generate URL-safe job ID."""
    return uuid.uuid4().hex[:12]

def get_job_dir(job_id: str) -> Path:
    """Get job directory path."""
    return DATA_DIR / job_id

def create_job_directory(
    smiles: str,
    isicle_version: str,
    nwchem_version: str
) -> JobStatus:
    """Create job directory with initial queued status."""
    job_id = generate_job_id()
    job_dir = get_job_dir(job_id)
    job_dir.mkdir(parents=True, exist_ok=True)
    (job_dir / 'output').mkdir(exist_ok=True)
    (job_dir / 'logs').mkdir(exist_ok=True)

    status = JobStatus(
        job_id=job_id,
        status='queued',
        created_at=datetime.utcnow(),
        input=JobInput(smiles=smiles),
        isicle_version=isicle_version,
        nwchem_version=nwchem_version,
    )

    _write_status(job_id, status)
    return status

def load_job_status(job_id: str) -> Optional[JobStatus]:
    """Load job status from disk. Returns None if not found."""
    status_file = get_job_dir(job_id) / 'status.json'
    if not status_file.exists():
        return None
    data = orjson.loads(status_file.read_bytes())
    return JobStatus.model_validate(data)

def update_job_status(job_id: str, **updates) -> JobStatus:
    """Update specific fields in job status."""
    status = load_job_status(job_id)
    if status is None:
        raise ValueError(f"Job {job_id} not found")
    updated = status.model_copy(update=updates)
    _write_status(job_id, updated)
    return updated

def _write_status(job_id: str, status: JobStatus) -> None:
    """Write status to disk."""
    status_file = get_job_dir(job_id) / 'status.json'
    status_file.write_bytes(
        orjson.dumps(
            status.model_dump(mode='json'),
            option=orjson.OPT_INDENT_2
        )
    )

def list_jobs_by_status(status_filter: str) -> list[str]:
    """List job IDs with given status."""
    jobs = []
    if not DATA_DIR.exists():
        return jobs
    for job_dir in DATA_DIR.iterdir():
        if not job_dir.is_dir():
            continue
        status = load_job_status(job_dir.name)
        if status and status.status == status_filter:
            jobs.append(job_dir.name)
    return jobs
```

Ensure DATA_DIR uses Path for cross-platform compatibility.
  </action>
  <verify>
```bash
uv run python -c "
from qm_nmr_calc.storage import create_job_directory, load_job_status, update_job_status
from datetime import datetime

# Create
job = create_job_directory('CCO', '2.0.0', '7.0.2')
print(f'Created job: {job.job_id}')

# Load
loaded = load_job_status(job.job_id)
print(f'Loaded status: {loaded.status}')

# Update
updated = update_job_status(job.job_id, status='running', started_at=datetime.utcnow())
print(f'Updated status: {updated.status}')

# Verify directory structure
from pathlib import Path
job_dir = Path(f'./data/jobs/{job.job_id}')
assert (job_dir / 'status.json').exists()
assert (job_dir / 'output').is_dir()
assert (job_dir / 'logs').is_dir()
print('Directory structure verified')
"
```
All assertions should pass.
  </verify>
  <done>
- create_job_directory creates proper structure (status.json, output/, logs/)
- load_job_status reads and validates status from disk
- update_job_status modifies specific fields
- Job ID generation produces URL-safe 12-character IDs
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `uv sync` succeeds
2. All imports work: `uv run python -c "from qm_nmr_calc.models import JobStatus; from qm_nmr_calc.storage import create_job_directory"`
3. Job creation workflow works end-to-end (create -> load -> update)
4. Job directories have correct structure
</verification>

<success_criteria>
- pyproject.toml with huey, pydantic, orjson, rdkit, isicle dependencies
- Working Pydantic models for JobStatus and JobInput
- Storage functions can create/read/update job status
- Job directories created with output/ and logs/ subdirectories
- All code passes type hints (no mypy errors on models/storage)
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
