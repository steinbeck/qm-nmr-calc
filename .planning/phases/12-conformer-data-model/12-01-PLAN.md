---
phase: 12-conformer-data-model
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/qm_nmr_calc/models.py
  - src/qm_nmr_calc/storage.py
  - tests/test_conformer_models.py
autonomous: true

must_haves:
  truths:
    - "System can represent a conformer with ID, energy (with units), and geometry path"
    - "System can represent an ensemble of conformers with method metadata"
    - "Each conformer gets isolated scratch directory under job_dir/scratch/conformers/{conf_id}/"
    - "Job directory has output/conformers/ and output/optimized/ subdirectories for multi-conformer jobs"
    - "JobStatus can optionally hold conformer ensemble data without breaking existing jobs"
  artifacts:
    - path: "src/qm_nmr_calc/models.py"
      provides: "ConformerData, ConformerEnsemble, EnergyUnit models"
      contains: "class ConformerData"
    - path: "src/qm_nmr_calc/storage.py"
      provides: "Per-conformer directory creation and path helpers"
      contains: "def get_conformer_scratch_dir"
    - path: "tests/test_conformer_models.py"
      provides: "Unit tests for conformer data models and storage"
      contains: "test_conformer_data_creation"
  key_links:
    - from: "src/qm_nmr_calc/storage.py"
      to: "src/qm_nmr_calc/models.py"
      via: "imports ConformerData, ConformerEnsemble"
      pattern: "from .models import.*ConformerData"
    - from: "src/qm_nmr_calc/models.py"
      to: "JobStatus"
      via: "optional conformer_ensemble field"
      pattern: "conformer_ensemble.*Optional\\[ConformerEnsemble\\]"
---

<objective>
Add conformer data models and per-conformer storage structure to support multi-conformer NMR calculations.

Purpose: This is the data foundation for v2.0 conformational sampling. All downstream phases (RDKit generation, Boltzmann averaging, NWChem loop, CREST) depend on these data structures to represent conformers and their associated energies, geometries, and scratch directories.

Output: ConformerData/ConformerEnsemble Pydantic models in models.py, per-conformer directory helpers in storage.py, and unit tests confirming both.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@src/qm_nmr_calc/models.py
@src/qm_nmr_calc/storage.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add conformer data models to models.py</name>
  <files>src/qm_nmr_calc/models.py</files>
  <action>
Add the following Pydantic models to models.py (after the existing NMRResults class, before StepTiming):

1. **EnergyUnit** - string enum/Literal for energy units:
   - `Literal["hartree", "kcal_mol", "kj_mol"]`

2. **ConformerData** - represents a single conformer:
   - `conformer_id`: str (e.g., "conf_001")
   - `energy`: Optional[float] = None (populated after DFT optimization)
   - `energy_unit`: Optional[EnergyUnit] = None
   - `weight`: Optional[float] = None (Boltzmann weight, populated after averaging)
   - `geometry_file`: Optional[str] = None (path relative to job dir, e.g., "output/conformers/conf_001.xyz")
   - `optimized_geometry_file`: Optional[str] = None (path relative to job dir)
   - `rmsd_from_ref`: Optional[float] = None (RMSD from lowest-energy conformer)
   - `status`: Literal["pending", "optimizing", "optimized", "nmr_running", "nmr_complete", "failed"] = "pending"
   - `error_message`: Optional[str] = None
   - Use `model_config = ConfigDict(strict=True)`

3. **ConformerEnsemble** - represents the full ensemble:
   - `method`: Literal["rdkit_kdg", "crest"] (generation method)
   - `conformers`: list[ConformerData] (the conformer list)
   - `temperature_k`: float = 298.15 (for Boltzmann weighting)
   - `pre_dft_energy_window_kcal`: float = 6.0 (pre-DFT filter threshold)
   - `post_dft_energy_window_kcal`: float = 3.0 (post-DFT filter threshold)
   - `total_generated`: int = 0 (before filtering)
   - `total_after_pre_filter`: int = 0
   - `total_after_post_filter`: int = 0
   - Use `model_config = ConfigDict(strict=True)`

4. **Update JobStatus** - add optional conformer ensemble field:
   - `conformer_ensemble`: Optional[ConformerEnsemble] = None
   - `conformer_mode`: Literal["single", "ensemble"] = "single"
   - These default to None/"single" so existing v1.x jobs load without issues

5. **Update JobInput** - add optional conformer parameters:
   - `conformer_mode`: Literal["single", "ensemble"] = "single"
   - `conformer_method`: Optional[Literal["rdkit_kdg", "crest"]] = None (only relevant when mode=ensemble)
   - `max_conformers`: Optional[int] = None (None = use adaptive default)

Important: Use Optional with defaults for ALL new fields to maintain backward compatibility with existing status.json files. The `extra="ignore"` on JobStatus already handles unknown fields, and Optional defaults handle missing fields.

Do NOT change any existing field types or defaults. Only add new fields.
  </action>
  <verify>
Run: `cd /home/chris/develop/qm-nmr-calc && python -c "from qm_nmr_calc.models import ConformerData, ConformerEnsemble, JobStatus, JobInput; print('Models import OK'); c = ConformerData(conformer_id='conf_001'); print(f'ConformerData: {c.conformer_id}'); e = ConformerEnsemble(method='rdkit_kdg', conformers=[c]); print(f'Ensemble: {e.method}, {len(e.conformers)} conformers'); j = JobStatus(job_id='test', status='queued', created_at='2024-01-01', input=JobInput(smiles='CCO', solvent='chcl3'), nwchem_version='7.0.2'); print(f'JobStatus conformer_mode: {j.conformer_mode}, ensemble: {j.conformer_ensemble}')"`

Expected: All imports succeed, defaults work, backward compat maintained.
  </verify>
  <done>ConformerData, ConformerEnsemble models exist in models.py. JobStatus has optional conformer_ensemble field defaulting to None. JobInput has conformer_mode defaulting to "single". All existing model behavior preserved.</done>
</task>

<task type="auto">
  <name>Task 2: Extend storage.py with per-conformer directory helpers</name>
  <files>src/qm_nmr_calc/storage.py</files>
  <action>
Add the following functions to storage.py (after the existing helper functions):

1. **`create_conformer_directories(job_id: str, conformer_ids: list[str]) -> dict[str, Path]`**
   - For each conformer_id, create:
     - `data/jobs/{job_id}/scratch/conformers/{conformer_id}/` (isolated NWChem scratch)
     - `data/jobs/{job_id}/output/conformers/{conformer_id}/` (per-conformer outputs)
   - Also create parent directories if they don't exist:
     - `data/jobs/{job_id}/output/optimized/` (for optimized geometries)
   - Returns dict mapping conformer_id -> scratch_dir Path
   - This prevents NWChem database file conflicts (Pitfall 5 from research)

2. **`get_conformer_scratch_dir(job_id: str, conformer_id: str) -> Path`**
   - Returns `data/jobs/{job_id}/scratch/conformers/{conformer_id}/`
   - Does NOT create the directory (caller should use create_conformer_directories first)

3. **`get_conformer_output_dir(job_id: str, conformer_id: str) -> Path`**
   - Returns `data/jobs/{job_id}/output/conformers/{conformer_id}/`

4. **`get_optimized_conformers_dir(job_id: str) -> Path`**
   - Returns `data/jobs/{job_id}/output/optimized/`

Update the import line to include ConformerData if needed for type hints, but keep it minimal -- these helpers work with strings (job_id, conformer_id), not model objects, to stay decoupled.

Do NOT modify existing functions (create_job_directory, get_job_dir, etc.). The new functions are additive only.
  </action>
  <verify>
Run: `cd /home/chris/develop/qm-nmr-calc && python -c "
from qm_nmr_calc.storage import create_conformer_directories, get_conformer_scratch_dir, get_conformer_output_dir, get_optimized_conformers_dir, DATA_DIR
import tempfile, os
from pathlib import Path
# Use temp dir to avoid polluting real data
old_data = DATA_DIR
import qm_nmr_calc.storage as st
st.DATA_DIR = Path(tempfile.mkdtemp()) / 'jobs'
st.DATA_DIR.mkdir(parents=True)
job_dir = st.DATA_DIR / 'test123'
job_dir.mkdir()
(job_dir / 'scratch').mkdir()
(job_dir / 'output').mkdir()
result = create_conformer_directories('test123', ['conf_001', 'conf_002', 'conf_003'])
print(f'Created dirs for {len(result)} conformers')
for cid, path in result.items():
    assert path.exists(), f'{path} does not exist'
    print(f'  {cid}: {path} exists={path.exists()}')
# Check output dirs too
for cid in ['conf_001', 'conf_002']:
    odir = get_conformer_output_dir('test123', cid)
    assert odir.exists(), f'{odir} does not exist'
opt_dir = get_optimized_conformers_dir('test123')
assert opt_dir.exists(), f'{opt_dir} does not exist'
print('All directory helpers work correctly')
st.DATA_DIR = old_data
"`

Expected: All directories created, paths correct.
  </verify>
  <done>Per-conformer scratch and output directory helpers exist in storage.py. create_conformer_directories creates isolated scratch dirs for each conformer. Helper functions return correct paths. Existing storage functions untouched.</done>
</task>

<task type="auto">
  <name>Task 3: Unit tests for conformer models and storage</name>
  <files>tests/test_conformer_models.py</files>
  <action>
Create tests/test_conformer_models.py with comprehensive tests for the new conformer data structures. Follow the existing test patterns (pytest classes, descriptive docstrings).

Test cases to include:

**ConformerData tests:**
- `test_conformer_data_creation` - create with just conformer_id, check defaults (energy=None, status="pending", etc.)
- `test_conformer_data_with_energy` - create with energy and energy_unit, verify values
- `test_conformer_data_status_transitions` - verify all valid status values accepted
- `test_conformer_data_invalid_status` - verify invalid status raises ValidationError
- `test_conformer_data_serialization` - model_dump and model_validate roundtrip

**ConformerEnsemble tests:**
- `test_ensemble_creation_minimal` - method + empty conformers list
- `test_ensemble_creation_with_conformers` - method + list of ConformerData
- `test_ensemble_defaults` - temperature=298.15, pre_dft=6.0, post_dft=3.0
- `test_ensemble_custom_parameters` - override temperature and energy windows
- `test_ensemble_serialization` - model_dump/model_validate roundtrip with conformers

**JobStatus backward compatibility tests:**
- `test_jobstatus_defaults_single_conformer` - new JobStatus has conformer_mode="single", ensemble=None
- `test_jobstatus_with_ensemble` - create JobStatus with conformer_ensemble populated
- `test_jobstatus_loads_v1_json` - create a dict mimicking v1.x status.json (no conformer fields), verify JobStatus.model_validate succeeds with defaults

**JobInput conformer fields tests:**
- `test_jobinput_defaults` - conformer_mode="single", conformer_method=None
- `test_jobinput_ensemble_mode` - conformer_mode="ensemble", conformer_method="rdkit_kdg"

**Storage directory tests (use tmp_path fixture):**
- `test_create_conformer_directories` - creates correct directory structure
- `test_conformer_scratch_isolation` - each conformer gets unique scratch dir
- `test_get_conformer_scratch_dir_path` - returns correct path
- `test_get_conformer_output_dir_path` - returns correct path
- `test_get_optimized_conformers_dir_path` - returns correct path

For storage tests, monkeypatch `qm_nmr_calc.storage.DATA_DIR` to `tmp_path / "jobs"` and create the basic job directory structure before testing.
  </action>
  <verify>
Run: `cd /home/chris/develop/qm-nmr-calc && python -m pytest tests/test_conformer_models.py -v`

Expected: All tests pass. No existing tests broken.

Then run: `cd /home/chris/develop/qm-nmr-calc && python -m pytest tests/ -v --tb=short`

Expected: Full test suite passes (all 95+ existing tests plus new tests).
  </verify>
  <done>tests/test_conformer_models.py exists with 15+ tests covering ConformerData, ConformerEnsemble, JobStatus backward compat, JobInput conformer fields, and storage directory helpers. All tests pass. No existing tests broken.</done>
</task>

</tasks>

<verification>
1. `python -c "from qm_nmr_calc.models import ConformerData, ConformerEnsemble"` succeeds
2. `python -c "from qm_nmr_calc.storage import create_conformer_directories, get_conformer_scratch_dir"` succeeds
3. `python -m pytest tests/test_conformer_models.py -v` -- all tests pass
4. `python -m pytest tests/ -v --tb=short` -- full suite passes (no regressions)
5. Existing v1.x status.json files (with no conformer fields) still load via `JobStatus.model_validate()`
</verification>

<success_criteria>
- ConformerData model captures conformer_id, energy (with unit), weight, geometry paths, and per-conformer status
- ConformerEnsemble model captures method, conformer list, temperature, energy windows, and filter counts
- JobStatus has optional conformer_ensemble and conformer_mode fields (backward compatible)
- JobInput has optional conformer_mode and conformer_method fields (backward compatible)
- Per-conformer scratch directories isolate NWChem runs (scratch/conformers/{conf_id}/)
- Per-conformer output directories exist (output/conformers/{conf_id}/)
- Optimized geometries directory exists (output/optimized/)
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/12-conformer-data-model/12-01-SUMMARY.md`
</output>
